Data Master
-----------

Induction on general population:
   d ("data") are i.i.d. with a p.d.f. p^*
   Model = p.d.f. or functions of p.d.f.
   Parametric model:
      P.d.f. belongs to a parametric class of p.d.f.
      P.d.f. of parameters: 
         Prior -> posterior (using the Bayesian theorem)
         Can be used in prediction (better than using a point estimator)
         Goodness of fit test
      Estimation of:
         Variance of a nominal attribute:
            H = \sum_i p_i^2  ("Homogeneity")
              \in (0,1]
              QV = 1 - H  ("Qualitative variance")
              1/H = k   "effective # categories"
                Proof: H = \sum_{i=1}^k (1/k)^2 = 1/k.
              Composition of 2 independent nominal variables:
                H = H_1 H_2
              Diploid organism: probability to be homozygous
            Entropy
            max p_i, where i \in categories
   Point estimators:
      Types:
         MAP ("Maximum Aposteriori Probability") estimator (= arg max P(parameters|d))
            P.d.f. of parameters
         MLE:
            L \eqdef P(d|parameters)
                Distribution of L?
            \hat parameters \eqdef arg max P(d|parameters) = arg min (- (1/|d|) * ln P(d|parameters))  // Average log likelihood
            lim_{|D| -> \infty} (- (1/|D|) * ln P(D|parameters)) = Entropy (D)
            E (- (1/|D|) * ln P(D|parameters)) = Entropy (D)
            Goodness of fit test:
               (- (1/|D|) * ln P(D|parameters)) asymptotically has a normal distribution (- E ln P(X|\hat parameters), 1/|d| var ln P(X|\hat parameters))
            Y \eqdef X/a (where a > 0) => - E ln P(Y) = - E ln P(X) - ln(a)
               Normalized entropy = Entropy - ln(\sqrt(Variance))
            lim_{|d| -> \infty} MLE = lim_{|d| -> \infty} MAP
            Parameter constraints may make \hat Entropy(d) worse, but are supposed to perform better in test
            Prove consistency -??
            L \eqdef \prod_i \phi(i|\alpha), where \alpha is a parameter
              ln L = \sum_i ln \phi(i|\alpha).
              {d ln L \over d \alpha} = \sum_i {{d \over d \alpha} \phi (i|\alpha) \over \phi(i|\alpha)} = 0.
              {d \over d \alpha} {d \over d \beta} ln L = 0 ??
         MP ("Mean Posterior") -??
         Bayesian estimator -??
         rank(x_i) vs. x_i: estimation of c.d.f. !??
      Optimization algorithm:
         Convergence
         Local optimality conditions hold => Algorithm converges?
         Algorithm converges => Local optimality conditions hold?
         Uniqueness of the optimum?
            Attaining global optimum
         Stability of the optimum:
            2nd order derivatives
            Cf. variance !??
      Variance of the estimator -> min
         Estimation of the estimator variance by comparing the estimates made using different samples of the same general population (consistency of estimator)
   Unbiased estimators: For averaging to reduce variance
   Interval estimation of parameters:
      Hypothesis testing (relationship to p^*)
      Stability of the optimum
   Identifying p.d.f.:
      List of p.d.f.; estimation of parameters; criterion; p.d.f. with the best goodness-of-fit p-value
      Goodness-of-fit tests:
         \hat Entropy_MLE on the traning set
         Difference of \hat Entropy_MLE on the traning and test sets
         Chi-square
         Kolmogorov-Smirnov
         Shapiro-Wilk
      Comparison of models:
         MAP: P(parameters|d)
         MLE: P(d|parameters)
   Using the posterior p.d.f. of a parameter vs. its point estimate:
      If the posterior p.d.f. is sharply peaked then use a point estimate, else use p.d.f. (such a parameter is a "nuisance")
   Outliers:
      Removing outliers:
         A method identifies outliers:        works faster
         A method does not identify outliers: works better
   Mixture of models
   Data Mining:
      Large set of hypotheses: arg min_hypothesis p-value(hypothesis)
      Interesting boolean condition: hypothesis: P(Class|Condition) = P(Class)
   Prediction: Using the objects where the values of the target attribute are missing:
      Algorithm:
         Replace missing values of the target attribute by a prior estimate;
         do 
           {
             Train using all objects; 
             Estimate the missing values of the target attribute;  // Likelihood is maximized -??!
           } 
         until the estimated missing values converge;
      Is it better than ignore the missing values?
      Significantly differs from conventional prediction if the number of missing values of the target attribute is relatively large
      If target attribute is BOOL_ATTR then it must be replaced by PROB_ATTR
      This method can be used in validation
      What if Test [] = true for all objects?
      PAC -??
   Decision-making: based on predicted probabilities and a loss function
   Universal models:
      Decision tree: easy overfitting
      Neural network
      Causal network
      Markov random field (log-linear model)
      Support vector machine


Data analysis method:
  Invariance properties:
    Reordering of objects
    Reordering of attributes
    Multiplicity (absolute frequency):
      Exchanging N identical objects with 1 object with mult = N
      Multiplicativeness: Multiplication of the multiplicity of each object by a real positive constant (uniform repetition of objects)
    NUM_ATTR with 2 values, NOM_ATTR with 2 categories, ORD_ATTR with 2 categories and BOOL_ATTR give the same analysis results



Object-attribute table (OAT):
   Comparison of 2 attributes:
      Independence tests
      Numerical-numerical:
         Correlation (pearson)
         Kendall's tau
         Spearman rho
      Nominal-Nominal:
         Contingency table
      Nominal-Numerical
      See "Business statistics"
   Dependence test (many attributes):
      Frequency << expected probability => logical dependence
      Find minimal subsets of linearly dependent attributes:
        Find linearly dependent rows of the VC matrix
   Same p.d.f. test:
      A set of Nominal attributes has the same distribution:
         Contingency table is a sufficient statistic
   Prediction:
      A conditional p.d.f. of the target attribute is known:
         Estimate parameters:
            MLE
            Minimize the mean loss:
               Loss \eqdef function of the distance between target and prediction:
                  Different "distances"
      A conditional (mutlivariate) p.d.f. of the factors given the target attribute is known:
         Estimate parameters
         Bayesian formula for prediction:
            The denominator: compute for different models: maximum denominator shows the best model
         P.d.f.:
            Normal ("Discriminant analysis")
            Kernel methods
      Find model with a best likelihood, but not with a best exogenous prediction evaluation function
      Reduce model to attain best generalization (see Vapnik)
      Variance of parameters
      Outliers
      Target and factors are numerical:
         regression
           model
             Linear
                Comparison of models: ANOVA
                Higher-order interactions  
             LOWESS: Locally Weighted linear regression
             LOESS: ??
             Non-linear 
             Orthogonal ??
           target variance at each object
             weight(object) := 1 / variance(object)
             weighted dependence of residuals on prediction
               must: 
                 mean = 0
                 variance = const
           outliers: objects with large residuals
           re-weighting procedure:
             variance(obj) := f(target)
             while not converges:
               compute prediction
               variance(obj) := f(prediction)
      Target is nominal:
         Target is Boolean:
            Quality:
               Minimizing the Loss function
               Penalties for false positive, false negative and non-prediction, possible awards for correct prediction
               The predicted probability of target is enough to make the decision
               Fixed penalties:
                        T   F
                  P     tp  fp
                  N     fn  tn
                  None  ?   ?
                  Sensitivity = tp / T = 1 - E_1 -> max
                  Specificity = tn / F = 1 - E_2 -> max  
                  Precision   = tp / P
                  Positive predictive value ("PPV") = tp / P
                  Negative predictive value ("NPV") = tn / N
                  Receiver Operating Characteristic ("ROC"): 
                     Plot: 
                        X: Sensitivity
                        Y: 1 - Specificity (= Imprecision) = fp / (tn + fp)
                     Points depend on one numerical parameter of the prediction procedure
                     "Big Gamma" shape is optimal
            Factors are numerical:
               Logistic regression:
                  Non-linear regression can be used
                  * Initial parameters:
                     Fisher's model
                     Linear regression
                     Mangasarian's model
                  A specific case of Neural Network
                  Other functions p(z) \in [0,1]
                  # FP = # FN -??
               Neural network:
                  Creating new attributes using the first level of a trained NN
      Method of potentials (Muchnik)
      Support vector machine (Vapnik):
         Simple
         Kernel-based
      Transductive Confidence Machine (Gammerman & Vovk, 2002):
         Confidence and credibility measure for each prediction
   Construction:
	    Reduction of dimensionality:
	       Factor analysis
      Clustering of objects:
         Outliers are in separate clusters
         Preceding by a "rough clustering" and applying the clustering to each rough cluster separately improves result
         Methods:
            Crisp clusters:
               K-means:
                  Model:
                     Mixture of multivariate normal p.d.f.
                     VC matrix for each cluster = identity matrix
                     Equal class probabilities
                     Caveat: Deterministic class assignment
               Minimize the p-value of the hypothesis that the multivariate p.d. are equal in all clusters
               Additional requirements: pairs of objects in one/different clusters
            Mixture decomposition:
               Data: 
                  VC in different clusters: different/same
                     VC is the same: centers must be different
                  Attributes: dependent/independent (VC is diagonal)
                  No constant attributes -??
                  Cluster membership is known for some objects
               t \eqdef number of clusters
               EM (MLE) given initial clusters:
                  Posterior -> Parameters
                  Posterior -> Prior
                  Prior, Parameters -> Posterior
                  Prior, Parameters -> p.d.f. -> Criterion (entropy)
               Initial clusters:
                  Should not be directed by the criteria of optimality of t
                  Create a new cluster:
                     Split a cluster using its first PC
                     Cluster of outliers -> new cluster:
                        Use non-parametric p.d.f.
                        See Rudzkis, Radavicius
                     Decomposition of 2 clusters with equal means -??
                  Merge clusters with close centers as long as their variance <= MaxClusterVariance
               Problems of EM algorithm:
                  Attaining optimality
                     Removing outliers, distant clusters improves clustering quality -??
                  Optimal t:
                     Find MLE for different t; test using statistics
                        Comparison of L(t) and L(t-1) (\chi^2 -??)
                        Likelihood of each cluster
                     Outliers make up separate clusters, but improve the criterion very little
                     Use extra knowledge about d, if |d| << \infty
                        Equal VC: test this hypothesis
               Global optimization for univariate case -??
               Entropy for a normal, for mixture of normals -??
               Test on model data
                  Difficult examples:
                     Equal or close centers
                     Small p_t
                  Compare with ClassMaster
               Representation of an arbitrary p.d.f. as a mixture of N(k*\mu,\sigma), k \in Z, p_k being a simple function of k.
                  Try to represent a Gamma p.d.f.
               Multivariate normal distributions:
                  Merge clusters into big clusters so that P(object in a big cluster) >= const \approx 1
            Hierarchical
      Clustering of attributes:
         Correlation
   Missing values:
      If all attributes for an object are missing then this object does not affect a data analysis
      Hypothesis: P.d.f. of missing values is the same as the p.d.f. of non-missing values (randomness of missing values)
      Fill in:
         Principal components (Mirkin)
         * Means
         Dempster et al., Maximum likelihood from incomplete data via the EM algorithm, J. R. Stat. Soc. B 39 (1977), 1-38
         Use values optimizing the criterion of an analysis method
   Auxiliary operations:
      Standardization
      Converting the types of attributes:
         Numeralization
         Ordinalization (including binarization)
   Multivariate nominal data:
      Mutidimensional contingency table
         Contingency table
            Confusion table: The same nominal attribute in rows and columns
            Tests:
               Chi^2:
                  Asymptotic
                  Why is the Chi^2 statistic is negatively monotone w.r.t. P(Table|H_0) ?
                  Why asymptotically Chi^2?
                  Table 2*2: Wald test statistic 
                  Why p-value(Chi^2) < p-value(Fisher) ?
               Fisher:
                  Conditional on both margins
                  Slow computation
               Barnard:
                  Conditional on one margin
                  Upper bound
                  Slow computation
               Fishers Exact-Boschloo
               Likelihood ratio
               G^2
            How far is the matrix rank from 1?
               "IPFP" -??


recognition of goal variables given data:
  while (var (goal variables) > threshold)
    request more data
    compute \phi(goal|data)


Decision-making -> Hypothesis testing
-------------------------------------
Two sets of \theta:
   \Theta_0 \cup \Theta_1 = all \theta
   \Theta_0 \cap \Theta_1 = \emptyset
   Usually: \Theta_0 is a small subset (singleton), simple interaction of parameters, independence
Decision: accept/reject \Theta_0 (or choose \Theta_0 or \Theta_1)
Loss function of (\Theta_i, Decision)
Criterion: Loss minimization
P(\Theta_0|d) = P(d|\Theta_0) * P(\Theta_0) \over P(d), where d - data.
P(d) = const (??) ==>
   Optimal decision given d is to reject \Theta_0 <==> P(\Theta_0|d) <= \alpha <==> P(d|\Theta_0) <= \beta = k * \alpha
      \alpha depends on the loss function, >= 0
      \beta >= 0
      Real rejection region := \{ d: P(d|\Theta_0) <= \beta \}
Rejection region of \Theta:
   R(\theta, \beta) := \{ d: P(d|\theta) <= \beta \}
      \beta_1 <= \beta_2 ==> R(\theta,\beta_1) \subset R(\theta,\beta_2)
   R(\Theta,\beta) := \cap_{\theta \in \Theta} R(\theta,\beta)
      \beta_1 <= \beta_2 ==> R(\Theta,\beta_1) \subset R(\Theta,\beta_2)
      R(\Theta,\beta) = \{ d: sup_{\theta \in \Theta} P(d|\theta) <= \beta \}
      P(d|\Theta) does not depend on \theta \in \Theta ==> R(\Theta,\beta) = R(\theta',\beta)
   Then \forall d \in R(\Theta,\beta) \forall \theta \in \Theta: P(d|\theta) <= \beta ==> 
      \forall d \in R(\Theta,\beta) for any distribution of \theta \in \Theta: P(d|\Theta) <= \beta
      R(\Theta_0,\beta) \subset Real rejection region
         P(d|\Theta) does not depend on \theta \in \Theta ==> R(\Theta_0,\beta) = Real rejection region
Error probability:
   For any distribuiton of \theta in \Theta:
      P(D \in R(\Theta,\beta)|\Theta) <= sup_{\theta \in \Theta} P(D \in R(\Theta,\beta)|\theta) =: E^max(\Theta,\beta) 
         |\Theta| = 1 ==> E^max(\Theta,\beta) = P(D \in R(\theta,\beta)|\theta)
   Type (i+1) error E_{i+1}^max(\beta) := E^max(\Theta_i,\beta) 
      Size of the test := E_1^max
         "Level of the test" >= E_1^max
      Power of the test := 1 - E_2^max
p-value:
   \beta(\Theta,d) := min \{ \beta: d \in R(\Theta,\beta) \}
      <==> \beta(\Theta,d) = sup_{\theta \in \Theta} P(d|\theta) >= P(d|\Theta) for any distribution of \theta in \Theta
         |\Theta| = 1 ==> \beta(\{\theta\},d) = P(d|\theta) 
         \beta(\Theta,d) decreases if the size of d increases
   R(\Theta,d) := R(\Theta, \beta(\Theta,d))
      \forall d: d \in R(\Theta,d) 
         d is on the "boundary" of R(\Theta,d)
   p-value(\Theta,d) := E^max(\Theta,\beta(\Theta,d))
      p-value is monotonic w.r.t. \beta(\Theta,d)
         p-value decreases if the size of d increases
      |\Theta| = 1 ==> p-value(\Theta,d) = P(P(D|\theta) <= P(d|\theta))
   \forall a: P(p-value(\theta,D) <= a) = a
      Validation of p-value
T(d) is positively monotone w.r.t. P(d|\theta) ==>
   p-value(\{\theta\}, d) = P(P_D(D|\theta) <= P(d|\theta)) = P(T(D) <= T(d))
P(d|\Theta) does not depend on \theta \in \Theta :<==> \exists \theta' \in \Theta \forall d: (\forall \theta \in \Theta: P(d|\theta) = P(d|\theta'))
   E.g., \Theta = \{\theta\}
??
"Conditional p-value":
   d = (d_1, d_2):
   P(\Theta_0|d) = P(\Theta_0|d_1,d_2) = P(d_2|\Theta_0,d_1) * P(\Theta_0|d_1) \over P(d_2|d_1) 
   P(\Theta_0|d_1) = P(\Theta_0), P(d_2|d_1) = const ==>
      \Theta_0 is rejected (decision) given d <==> P(\Theta_0|d) < \alpha <==> P(d_2|\Theta_0,d_1) < \beta = k * \alpha
??
Multiple testing correction

   

Time series:
   For each point: Different time interval when the process occurred
   1-attribute analysis:
      Durbin-Watson
      Periodicity (spectrum)
      Smoothing
   Modeling
   Signal detection: 
      Mixture decomposition
      Kalman filter
      
Image processing
   Spatial data

Application of methods to a p.d.f. instead of data

Testing (resampling)

Dependence of a numerical attribute on nominal attributes:
   Additive model
   Cf. linear regression
   ANOVA
   H_0: dependence on one nominal attribute: what test is better (2-way ANOVA, 1-way ANOVA, a different test)?

Selection the complexity level of p.d.f.:
   Training/validation/test sets
   Find non-significant parameters
   
Problems:
   Estimation of variability of a nominal variable
      Gini meaure: 
         Unbiased
         Confidence interval -??
      Application: Complexity of DNA, peptides

Graphics:
   Visual data analysis
   Histogram: use kernel methods; confidence interval (3 curves)
      "Loess" curve -??
      Parzen "functions", choice of variance to best fit the original pdf


